{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data can not convert to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2e23dfb6d96e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mimagem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'madfox.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmadfox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmadfox\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gabriel Moura\\Anaconda3\\envs\\python2amb\\lib\\site-packages\\matplotlib\\pyplot.pyc\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3155\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3156\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3157\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3158\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gabriel Moura\\Anaconda3\\envs\\python2amb\\lib\\site-packages\\matplotlib\\__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1895\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1896\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1898\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gabriel Moura\\Anaconda3\\envs\\python2amb\\lib\\site-packages\\matplotlib\\axes\\_axes.pyc\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5122\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5124\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5125\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Gabriel Moura\\Anaconda3\\envs\\python2amb\\lib\\site-packages\\matplotlib\\image.pyc\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    594\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    595\u001b[0m                 not np.can_cast(self._A.dtype, np.float)):\n\u001b[1;32m--> 596\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image data can not convert to float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         if (self._A.ndim not in (2, 3) or\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data can not convert to float"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADCtJREFUeJzt21+IZvV9x/H3p7tZaEwaJTsJ6e5Kt2WNbttYdGIkhNY0\ntO6aiyXghRoqlcAixJBLpdCk4E1zUQjBP8sii+QmexNJN2UTW1oSC9bGWVDXVZTpSt1VwVVDCgYq\ng99ezNP0yXx3d86szzzPTn2/YGDOOb+Z82WY5z1nzpxJVSFJ435j1gNIuvgYBkmNYZDUGAZJjWGQ\n1BgGSc2qYUhyKMnrSZ49x/Ek+U6SxSTPJLlm8mNKmqYhVwwPA3vOc3wvsGv0th948L2PJWmWVg1D\nVT0GvHWeJfuA79ayJ4BLk3xiUgNKmr7NE/gc24BTY9unR/teW7kwyX6Wryq45JJLrr3yyisncHpJ\n53Ls2LE3qmpurR83iTAMVlUHgYMA8/PztbCwMM3TS+87Sf7zQj5uEn+VeAXYMba9fbRP0gY1iTAc\nAW4f/XXieuAXVdV+jZC0caz6q0SS7wE3AFuTnAa+CXwAoKoOAEeBm4BF4JfAHes1rKTpWDUMVXXr\nKscL+OrEJpI0cz75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkx\nDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEM\nkhrDIKkxDJIawyCpMQySGsMgqRkUhiR7kryQZDHJPWc5/pEkP0zydJITSe6Y/KiSpmXVMCTZBNwP\n7AV2A7cm2b1i2VeB56rqauAG4O+SbJnwrJKmZMgVw3XAYlWdrKp3gMPAvhVrCvhwkgAfAt4CliY6\nqaSpGRKGbcCpse3To33j7gOuAl4FjgNfr6p3V36iJPuTLCRZOHPmzAWOLGm9Term443AU8BvA38E\n3Jfkt1YuqqqDVTVfVfNzc3MTOrWkSRsShleAHWPb20f7xt0BPFLLFoGXgCsnM6KkaRsShieBXUl2\njm4o3gIcWbHmZeALAEk+DnwSODnJQSVNz+bVFlTVUpK7gEeBTcChqjqR5M7R8QPAvcDDSY4DAe6u\nqjfWcW5J62jVMABU1VHg6Ip9B8befxX488mOJmlWfPJRUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMY\nJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgk\nNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1g8KQZE+SF5IsJrnnHGtuSPJUkhNJ\nfjrZMSVN0+bVFiTZBNwP/BlwGngyyZGqem5szaXAA8Ceqno5ycfWa2BJ62/IFcN1wGJVnayqd4DD\nwL4Va24DHqmqlwGq6vXJjilpmoaEYRtwamz79GjfuCuAy5L8JMmxJLef7RMl2Z9kIcnCmTNnLmxi\nSetuUjcfNwPXAl8EbgT+OskVKxdV1cGqmq+q+bm5uQmdWtKkrXqPAXgF2DG2vX20b9xp4M2qeht4\nO8ljwNXAixOZUtJUDblieBLYlWRnki3ALcCRFWv+Hvhcks1JPgh8Bnh+sqNKmpZVrxiqainJXcCj\nwCbgUFWdSHLn6PiBqno+yY+BZ4B3gYeq6tn1HFzS+klVzeTE8/PztbCwMJNzS+8XSY5V1fxaP84n\nHyU1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMY\nJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgk\nNYZBUmMYJDWDwpBkT5IXkiwmuec86z6dZCnJzZMbUdK0rRqGJJuA+4G9wG7g1iS7z7HuW8A/TnpI\nSdM15IrhOmCxqk5W1TvAYWDfWdZ9Dfg+8PoE55M0A0PCsA04NbZ9erTvV5JsA74EPHi+T5Rkf5KF\nJAtnzpxZ66ySpmRSNx+/DdxdVe+eb1FVHayq+aqan5ubm9CpJU3a5gFrXgF2jG1vH+0bNw8cTgKw\nFbgpyVJV/WAiU0qaqiFheBLYlWQny0G4BbhtfEFV7fzf95M8DPyDUZA2rlXDUFVLSe4CHgU2AYeq\n6kSSO0fHD6zzjJKmbMgVA1V1FDi6Yt9Zg1BVf/nex5I0Sz75KKkxDJIawyCpMQySGsMgqTEMkhrD\nIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMg\nqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLInyQtJFpPcc5bjX07y\nTJLjSR5PcvXkR5U0LauGIckm4H5gL7AbuDXJ7hXLXgL+pKr+ELgXODjpQSVNz5ArhuuAxao6WVXv\nAIeBfeMLqurxqvr5aPMJYPtkx5Q0TUPCsA04NbZ9erTvXL4C/OhsB5LsT7KQZOHMmTPDp5Q0VRO9\n+Zjk8yyH4e6zHa+qg1U1X1Xzc3Nzkzy1pAnaPGDNK8COse3to32/JsmngIeAvVX15mTGkzQLQ64Y\nngR2JdmZZAtwC3BkfEGSy4FHgL+oqhcnP6akaVr1iqGqlpLcBTwKbAIOVdWJJHeOjh8AvgF8FHgg\nCcBSVc2v39iS1lOqaiYnnp+fr4WFhZmcW3q/SHLsQn5I++SjpMYwSGoMg6TGMEhqDIOkxjBIagyD\npMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOk\nxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkZlAYkuxJ8kKSxST3nOV4\nknxndPyZJNdMflRJ07JqGJJsAu4H9gK7gVuT7F6xbC+wa/S2H3hwwnNKmqIhVwzXAYtVdbKq3gEO\nA/tWrNkHfLeWPQFcmuQTE55V0pRsHrBmG3BqbPs08JkBa7YBr40vSrKf5SsKgP9O8uyapp2trcAb\nsx5ioI00K2yseTfSrACfvJAPGhKGiamqg8BBgCQLVTU/zfO/Fxtp3o00K2yseTfSrLA874V83JBf\nJV4Bdoxtbx/tW+saSRvEkDA8CexKsjPJFuAW4MiKNUeA20d/nbge+EVVvbbyE0naGFb9VaKqlpLc\nBTwKbAIOVdWJJHeOjh8AjgI3AYvAL4E7Bpz74AVPPRsbad6NNCtsrHk30qxwgfOmqiY9iKQNzicf\nJTWGQVKz7mHYSI9TD5j1y6MZjyd5PMnVs5hzbJ7zzju27tNJlpLcPM35Vsyw6qxJbkjyVJITSX46\n7RlXzLLa98JHkvwwydOjeYfcV1sXSQ4lef1czwVd0GusqtbtjeWblf8B/C6wBXga2L1izU3Aj4AA\n1wP/vp4zvcdZPwtcNnp/76xmHTrv2Lp/YfkG8c0X66zApcBzwOWj7Y9dzF9b4K+Ab43enwPeArbM\naN4/Bq4Bnj3H8TW/xtb7imEjPU696qxV9XhV/Xy0+QTLz2vMypCvLcDXgO8Dr09zuBWGzHob8EhV\nvQxQVRf7vAV8OEmAD7EchqXpjjkapOqx0fnPZc2vsfUOw7kelV7rmmlY6xxfYbnCs7LqvEm2AV9i\n9v/UNuRrewVwWZKfJDmW5PapTdcNmfc+4CrgVeA48PWqenc6463Zml9jU30k+v+LJJ9nOQyfm/Us\nq/g2cHdVvbv8g+2ithm4FvgC8JvAvyV5oqpenO1Y53Qj8BTwp8DvAf+U5F+r6r9mO9ZkrHcYNtLj\n1IPmSPIp4CFgb1W9OaXZzmbIvPPA4VEUtgI3JVmqqh9MZ8RfGTLraeDNqnobeDvJY8DVwCzCMGTe\nO4C/reVf4heTvARcCfxsOiOuydpfY+t8U2QzcBLYyf/dxPn9FWu+yK/fGPnZjG7gDJn1cpaf7vzs\nLGZc67wr1j/M7G4+DvnaXgX882jtB4FngT+4iOd9EPib0fsfH73Qts7w++F3OPfNxzW/xtb1iqHW\n73HqWc36DeCjwAOjn8JLNaP/tBs470VhyKxV9XySHwPPAO8CD1XVTP4tf+DX9l7g4STHWX7B3V1V\nM/l37CTfA24AtiY5DXwT+MDYrGt+jflItKTGJx8lNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNf8DUTBP\njjp5sn4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1033ed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import matplotlib.cm as cm\n",
    "from math import pi\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "imagem = 'madfox.jpg'\n",
    "madfox = cv2.imread(imagem, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "lower = 0\n",
    "upper = 1\n",
    "# Returns an image containing the borders of the image\n",
    "# sigma is how far from the median we are setting the thresholds\n",
    "\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "\n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # A gaussian blur to get rid of the noise in the image\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    #blur = gray\n",
    "    # Detect the edges present in the image\n",
    "    bordas = auto_canny(blur)\n",
    "\n",
    "\n",
    "    circles = []\n",
    "\n",
    "\n",
    "    # Obtains a version of the edges image where we can draw in color\n",
    "    bordas_color = cv2.cvtColor(bordas, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # HoughCircles - detects circles using the Hough Method. For an explanation of\n",
    "    # param1 and param2 please see an explanation here http://www.pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "    circles = None\n",
    "    circles=cv2.HoughCircles(bordas,cv2.HOUGH_GRADIENT,2,40,param1=50,param2=100,minRadius=5,maxRadius=60)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0,:]:\n",
    "            # draw the outer circle\n",
    "            # cv2.circle(img, center, radius, color[, thickness[, lineType[, shift]]])\n",
    "            cv2.circle(bordas_color,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "            # draw the center of the circle\n",
    "            cv2.circle(bordas_color,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "    # Draw a diagonal blue line with thickness of 5 px\n",
    "    # cv2.line(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "    cv2.line(bordas_color,(0,0),(511,511),(255,0,0),5)\n",
    "\n",
    "    # cv2.rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "    cv2.rectangle(bordas_color,(384,0),(510,128),(0,255,0),3)    \n",
    "        \n",
    "    ###FIM DO CÓDIGO DOS CIRCULOS###\n",
    "    \n",
    "    \n",
    "    MIN_MATCH_COUNT = 10\n",
    "    img1 = cv2.imread(imagem,0)          # Imagem a procurar\n",
    "    img2 = frame # Imagem do cenario - puxe do video para fazer isto\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT in each image\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    # Configura o algoritmo de casamento de features\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Tenta fazer a melhor comparacao usando o algoritmo\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        # Separa os bons matches na origem e no destino\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "        # Tenta achar uma trasformacao composta de rotacao, translacao e escala que situe uma imagem na outra\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "\n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "        # Transforma os pontos da imagem origem para onde estao na imagem destino\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "        # Desenha as linhas\n",
    "        img2b = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "        \n",
    "        # cv2.putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(bordas_color,'MaDFoX',(0,50), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "    else:\n",
    "        matchesMask = None\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                       singlePointColor = None,\n",
    "                       matchesMask = matchesMask, # draw only inliers\n",
    "                       flags = 2)\n",
    "    \n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Detector de circulos',bordas_color)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
